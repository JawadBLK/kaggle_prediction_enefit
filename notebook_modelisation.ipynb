{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import json \n",
    "import sklearn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_small = pd.read_csv('./data_transformed/train_500_2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>is_business</th>\n",
       "      <th>product_type</th>\n",
       "      <th>target</th>\n",
       "      <th>is_consumption</th>\n",
       "      <th>data_block_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>prediction_unit_id</th>\n",
       "      <th>price_elec</th>\n",
       "      <th>temperature</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>average_lowest_gas_price</th>\n",
       "      <th>average_highest_gas_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>790.836</td>\n",
       "      <td>1</td>\n",
       "      <td>449</td>\n",
       "      <td>1414989</td>\n",
       "      <td>45</td>\n",
       "      <td>199.99</td>\n",
       "      <td>-4.8</td>\n",
       "      <td>2022</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>121.00</td>\n",
       "      <td>137.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.396</td>\n",
       "      <td>0</td>\n",
       "      <td>305</td>\n",
       "      <td>953684</td>\n",
       "      <td>37</td>\n",
       "      <td>211.31</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>146.50</td>\n",
       "      <td>155.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>103626</td>\n",
       "      <td>16</td>\n",
       "      <td>98.25</td>\n",
       "      <td>8.7</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>65.11</td>\n",
       "      <td>66.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>551</td>\n",
       "      <td>1745132</td>\n",
       "      <td>59</td>\n",
       "      <td>129.23</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>51.00</td>\n",
       "      <td>54.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>620</td>\n",
       "      <td>1961232</td>\n",
       "      <td>29</td>\n",
       "      <td>85.59</td>\n",
       "      <td>9.4</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>38.60</td>\n",
       "      <td>41.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>253</td>\n",
       "      <td>786780</td>\n",
       "      <td>1</td>\n",
       "      <td>54.10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>98.00</td>\n",
       "      <td>104.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>59.062</td>\n",
       "      <td>0</td>\n",
       "      <td>293</td>\n",
       "      <td>914348</td>\n",
       "      <td>1</td>\n",
       "      <td>199.04</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>110.05</td>\n",
       "      <td>125.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>902.756</td>\n",
       "      <td>1</td>\n",
       "      <td>268</td>\n",
       "      <td>833853</td>\n",
       "      <td>17</td>\n",
       "      <td>109.55</td>\n",
       "      <td>7.6</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>102.00</td>\n",
       "      <td>121.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1935.450</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>188631</td>\n",
       "      <td>56</td>\n",
       "      <td>119.38</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2021</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>59.00</td>\n",
       "      <td>87.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.296</td>\n",
       "      <td>0</td>\n",
       "      <td>468</td>\n",
       "      <td>1479476</td>\n",
       "      <td>20</td>\n",
       "      <td>351.72</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>139.00</td>\n",
       "      <td>157.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        county  is_business  product_type    target  is_consumption  \\\n",
       "0           11            0             3   790.836               1   \n",
       "1            9            1             3     4.396               0   \n",
       "2            4            0             3     0.000               0   \n",
       "3           15            1             1     0.000               0   \n",
       "4            7            1             1     0.000               0   \n",
       "...        ...          ...           ...       ...             ...   \n",
       "499995       0            0             2     0.000               0   \n",
       "499996       0            0             2    59.062               0   \n",
       "499997       4            1             0   902.756               1   \n",
       "499998      14            1             3  1935.450               1   \n",
       "499999       5            0             3     0.296               0   \n",
       "\n",
       "        data_block_id   row_id  prediction_unit_id  price_elec  temperature  \\\n",
       "0                 449  1414989                  45      199.99         -4.8   \n",
       "1                 305   953684                  37      211.31         19.0   \n",
       "2                  35   103626                  16       98.25          8.7   \n",
       "3                 551  1745132                  59      129.23         -4.0   \n",
       "4                 620  1961232                  29       85.59          9.4   \n",
       "...               ...      ...                 ...         ...          ...   \n",
       "499995            253   786780                   1       54.10         10.0   \n",
       "499996            293   914348                   1      199.04         12.5   \n",
       "499997            268   833853                  17      109.55          7.6   \n",
       "499998             63   188631                  56      119.38          5.3   \n",
       "499999            468  1479476                  20      351.72         -2.2   \n",
       "\n",
       "        year  month  day  hour  average_lowest_gas_price  \\\n",
       "0       2022     11   24     1                    121.00   \n",
       "1       2022      7    3    21                    146.50   \n",
       "2       2021     10    6     5                     65.11   \n",
       "3       2023      3    6    19                     51.00   \n",
       "4       2023      5   14     2                     38.60   \n",
       "...      ...    ...  ...   ...                       ...   \n",
       "499995  2022      5   12    23                     98.00   \n",
       "499996  2022      6   21    15                    110.05   \n",
       "499997  2022      5   27    14                    102.00   \n",
       "499998  2021     11    3     7                     59.00   \n",
       "499999  2022     12   13    22                    139.00   \n",
       "\n",
       "        average_highest_gas_price  \n",
       "0                          137.99  \n",
       "1                          155.00  \n",
       "2                           66.60  \n",
       "3                           54.45  \n",
       "4                           41.65  \n",
       "...                           ...  \n",
       "499995                     104.12  \n",
       "499996                     125.00  \n",
       "499997                     121.95  \n",
       "499998                      87.90  \n",
       "499999                     157.00  \n",
       "\n",
       "[500000 rows x 16 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        county  is_business  product_type   target  is_consumption  \\\n",
      "410          7            1             1   21.889               0   \n",
      "2900         4            0             3  128.483               0   \n",
      "3372         3            0             3    6.037               1   \n",
      "3565         7            0             1    8.261               1   \n",
      "4599         9            1             3   79.820               1   \n",
      "...        ...          ...           ...      ...             ...   \n",
      "498592       0            1             1    2.133               0   \n",
      "499271      10            0             1   11.351               1   \n",
      "499356       2            0             3    0.000               0   \n",
      "499394       8            0             1   11.895               1   \n",
      "499431       9            1             3  180.818               0   \n",
      "\n",
      "        data_block_id  row_id  prediction_unit_id  price_elec  temperature  \\\n",
      "410                 0    2254                  29      138.00         13.6   \n",
      "2900                0    1984                  16      112.44         13.9   \n",
      "3372                0    1855                  12      105.05         14.7   \n",
      "3565                0    1149                  25      130.80         13.6   \n",
      "4599                0    2149                  37      122.66         14.0   \n",
      "...               ...     ...                 ...         ...          ...   \n",
      "498592              0    2326                   4      158.51         13.2   \n",
      "499271              0    2273                  38      138.00         13.6   \n",
      "499356              0      18                   9       96.99         14.5   \n",
      "499394              0    2747                  31       87.45          9.7   \n",
      "499431              0    1660                  37      100.99         14.8   \n",
      "\n",
      "        year  month  day  hour  average_lowest_gas_price  \\\n",
      "410     2021      9    1    18                       0.0   \n",
      "2900    2021      9    1    16                       0.0   \n",
      "3372    2021      9    1    15                       0.0   \n",
      "3565    2021      9    1     9                       0.0   \n",
      "4599    2021      9    1    17                       0.0   \n",
      "...      ...    ...  ...   ...                       ...   \n",
      "498592  2021      9    1    19                       0.0   \n",
      "499271  2021      9    1    18                       0.0   \n",
      "499356  2021      9    1     0                       0.0   \n",
      "499394  2021      9    1    22                       0.0   \n",
      "499431  2021      9    1    13                       0.0   \n",
      "\n",
      "        average_highest_gas_price  \n",
      "410                           0.0  \n",
      "2900                          0.0  \n",
      "3372                          0.0  \n",
      "3565                          0.0  \n",
      "4599                          0.0  \n",
      "...                           ...  \n",
      "498592                        0.0  \n",
      "499271                        0.0  \n",
      "499356                        0.0  \n",
      "499394                        0.0  \n",
      "499431                        0.0  \n",
      "\n",
      "[715 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "# Supposons que df_train soit votre DataFrame\n",
    "\n",
    "# Colonne pour laquelle vous souhaitez afficher les valeurs nulles\n",
    "col_name = 'average_lowest_gas_price'\n",
    "\n",
    "# Afficher les valeurs nulles dans la colonne spécifiée\n",
    "null_values = df_train_small[col_name].isnull()\n",
    "\n",
    "# Afficher les lignes où la valeur est nulle\n",
    "print(df_train_small[null_values])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   county  is_business  product_type   target  is_consumption  data_block_id  \\\n",
      "0      11            0             3  790.836               1            449   \n",
      "1       9            1             3    4.396               0            305   \n",
      "2       4            0             3    0.000               0             35   \n",
      "3      15            1             1    0.000               0            551   \n",
      "4       7            1             1    0.000               0            620   \n",
      "\n",
      "    row_id  prediction_unit_id  price_elec  temperature  year  month  day  \\\n",
      "0  1414989                  45      199.99         -4.8  2022     11   24   \n",
      "1   953684                  37      211.31         19.0  2022      7    3   \n",
      "2   103626                  16       98.25          8.7  2021     10    6   \n",
      "3  1745132                  59      129.23         -4.0  2023      3    6   \n",
      "4  1961232                  29       85.59          9.4  2023      5   14   \n",
      "\n",
      "   hour  average_lowest_gas_price  average_highest_gas_price  \n",
      "0     1                    121.00                     137.99  \n",
      "1    21                    146.50                     155.00  \n",
      "2     5                     65.11                      66.60  \n",
      "3    19                     51.00                      54.45  \n",
      "4     2                     38.60                      41.65  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jawad\\AppData\\Local\\Temp\\ipykernel_21628\\146887180.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train_small['average_highest_gas_price'].fillna(0, inplace=True)\n",
      "C:\\Users\\Jawad\\AppData\\Local\\Temp\\ipykernel_21628\\146887180.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train_small['average_lowest_gas_price'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Supposons que df_train soit votre DataFrame\n",
    "\n",
    "# Remplacer les NaN par \"0\" dans les colonnes spécifiées\n",
    "df_train_small['average_highest_gas_price'].fillna(0, inplace=True)\n",
    "df_train_small['average_lowest_gas_price'].fillna(0, inplace=True)\n",
    "\n",
    "# Afficher les premières lignes du DataFrame df_train après le remplacement\n",
    "print(df_train_small.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "county                       0\n",
       "is_business                  0\n",
       "product_type                 0\n",
       "target                       0\n",
       "is_consumption               0\n",
       "data_block_id                0\n",
       "row_id                       0\n",
       "prediction_unit_id           0\n",
       "price_elec                   0\n",
       "temperature                  0\n",
       "year                         0\n",
       "month                        0\n",
       "day                          0\n",
       "hour                         0\n",
       "average_lowest_gas_price     0\n",
       "average_highest_gas_price    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_small.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all lines where target is null or nan\n",
    "# A function 'dropna' exists also\n",
    "df_train_small = df_train_small[df_train_small[\"target\"].isna() == False]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train - Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_train_small.drop('target', axis=1)\n",
    "y = df_train_small['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>is_business</th>\n",
       "      <th>product_type</th>\n",
       "      <th>is_consumption</th>\n",
       "      <th>data_block_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>prediction_unit_id</th>\n",
       "      <th>price_elec</th>\n",
       "      <th>temperature</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>average_lowest_gas_price</th>\n",
       "      <th>average_highest_gas_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>427040</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>80124</td>\n",
       "      <td>46</td>\n",
       "      <td>190.20</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>49.51</td>\n",
       "      <td>54.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349577</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>573</td>\n",
       "      <td>1812649</td>\n",
       "      <td>3</td>\n",
       "      <td>53.49</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>43.00</td>\n",
       "      <td>48.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276127</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>632</td>\n",
       "      <td>2001790</td>\n",
       "      <td>61</td>\n",
       "      <td>55.08</td>\n",
       "      <td>12.1</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>30.00</td>\n",
       "      <td>35.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23230</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>396</td>\n",
       "      <td>1241534</td>\n",
       "      <td>27</td>\n",
       "      <td>357.80</td>\n",
       "      <td>9.7</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>185.00</td>\n",
       "      <td>201.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391151</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>231</td>\n",
       "      <td>712630</td>\n",
       "      <td>35</td>\n",
       "      <td>30.42</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>96.76</td>\n",
       "      <td>119.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259243</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>403</td>\n",
       "      <td>1264432</td>\n",
       "      <td>51</td>\n",
       "      <td>372.19</td>\n",
       "      <td>9.7</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>130.00</td>\n",
       "      <td>144.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365935</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>594</td>\n",
       "      <td>1879802</td>\n",
       "      <td>46</td>\n",
       "      <td>35.36</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2023</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>47.21</td>\n",
       "      <td>51.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131963</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>570</td>\n",
       "      <td>1804046</td>\n",
       "      <td>16</td>\n",
       "      <td>49.62</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>43.10</td>\n",
       "      <td>46.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146904</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>469</td>\n",
       "      <td>1480577</td>\n",
       "      <td>34</td>\n",
       "      <td>338.54</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>131.01</td>\n",
       "      <td>157.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121987</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>508</td>\n",
       "      <td>1607550</td>\n",
       "      <td>30</td>\n",
       "      <td>114.40</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>61.00</td>\n",
       "      <td>70.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399896 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        county  is_business  product_type  is_consumption  data_block_id  \\\n",
       "427040      11            1             1               0             27   \n",
       "349577       0            1             0               1            573   \n",
       "276127       0            1             2               0            632   \n",
       "23230        7            0             3               0            396   \n",
       "391151       9            0             3               0            231   \n",
       "...        ...          ...           ...             ...            ...   \n",
       "259243      13            0             3               0            403   \n",
       "365935      11            1             1               0            594   \n",
       "131963       4            0             3               0            570   \n",
       "146904       9            0             1               1            469   \n",
       "121987       7            1             3               0            508   \n",
       "\n",
       "         row_id  prediction_unit_id  price_elec  temperature  year  month  \\\n",
       "427040    80124                  46      190.20          8.5  2021      9   \n",
       "349577  1812649                   3       53.49         -1.8  2023      3   \n",
       "276127  2001790                  61       55.08         12.1  2023      5   \n",
       "23230   1241534                  27      357.80          9.7  2022     10   \n",
       "391151   712630                  35       30.42          5.7  2022      4   \n",
       "...         ...                 ...         ...          ...   ...    ...   \n",
       "259243  1264432                  51      372.19          9.7  2022     10   \n",
       "365935  1879802                  46       35.36          4.6  2023      4   \n",
       "131963  1804046                  16       49.62          3.9  2023      3   \n",
       "146904  1480577                  34      338.54         14.0  2022     12   \n",
       "121987  1607550                  30      114.40         -4.6  2023      1   \n",
       "\n",
       "        day  hour  average_lowest_gas_price  average_highest_gas_price  \n",
       "427040   28     8                     49.51                      54.76  \n",
       "349577   28     3                     43.00                      48.50  \n",
       "276127   26    17                     30.00                      35.00  \n",
       "23230     2     6                    185.00                     201.60  \n",
       "391151   20     1                     96.76                     119.99  \n",
       "...     ...   ...                       ...                        ...  \n",
       "259243    9     6                    130.00                     144.29  \n",
       "365935   18    12                     47.21                      51.49  \n",
       "131963   25    10                     43.10                      46.99  \n",
       "146904   14     6                    131.01                     157.00  \n",
       "121987   22    19                     61.00                      70.15  \n",
       "\n",
       "[399896 rows x 15 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DummyRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyRegressor</label><div class=\"sk-toggleable__content\"><pre>DummyRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DummyRegressor()"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrainement \n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "dummy_regr = DummyRegressor(strategy=\"mean\")\n",
    "dummy_regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DummyRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyRegressor</label><div class=\"sk-toggleable__content\"><pre>DummyRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DummyRegressor()"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test \n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "dummy_regr_test = DummyRegressor(strategy=\"mean\")\n",
    "dummy_regr_test.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainement \n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "y_train_hat = reg.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test \n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg_test = LinearRegression().fit(X_test, y_test)\n",
    "y_train_hat = reg_test.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.132e+11, tolerance: 2.578e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.145e+11, tolerance: 2.615e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.145e+11, tolerance: 2.605e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.157e+11, tolerance: 2.634e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.143e+11, tolerance: 2.604e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.100e+11, tolerance: 2.578e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.116e+11, tolerance: 2.615e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.119e+11, tolerance: 2.605e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.137e+11, tolerance: 2.634e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.121e+11, tolerance: 2.604e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.323e+10, tolerance: 2.578e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.232e+10, tolerance: 2.615e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.930e+10, tolerance: 2.605e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.059e+10, tolerance: 2.634e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.473e+10, tolerance: 2.604e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.400e+11, tolerance: 3.259e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.400e+11, tolerance: 3.259e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso(alpha=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso(alpha=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Lasso(alpha=0.1)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrainement \n",
    "# recherche des meilleurs paramètres\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "lasso = Lasso()\n",
    "\n",
    "grid_search = GridSearchCV(lasso, parameters, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "BestAlpha = grid_search.best_params_['alpha']\n",
    "\n",
    "# entraînement du modèle\n",
    "BestLasso = Lasso(alpha=BestAlpha)\n",
    "BestLasso.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  meilleur modèle pour prédire le premier dataset\n",
    "lasso_res = BestLasso.predict(X_train)\n",
    "\n",
    "# marge d'erreur du modèle\n",
    "lasso = abs(lasso_res - y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.132e+11, tolerance: 2.578e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.145e+11, tolerance: 2.615e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.145e+11, tolerance: 2.605e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.157e+11, tolerance: 2.634e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.143e+11, tolerance: 2.604e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.100e+11, tolerance: 2.578e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.116e+11, tolerance: 2.615e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.119e+11, tolerance: 2.605e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.137e+11, tolerance: 2.634e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.121e+11, tolerance: 2.604e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.323e+10, tolerance: 2.578e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.232e+10, tolerance: 2.615e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.930e+10, tolerance: 2.605e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.059e+10, tolerance: 2.634e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.473e+10, tolerance: 2.604e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.400e+11, tolerance: 3.259e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.400e+11, tolerance: 3.259e+07\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "parameters = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "lasso = Lasso()\n",
    "\n",
    "grid_search = GridSearchCV(lasso, parameters, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "BestAlpha = grid_search.best_params_['alpha']\n",
    "\n",
    "# entraînement du modèle\n",
    "BestLasso_test = Lasso(alpha=BestAlpha)\n",
    "BestLasso_test.fit(X_train, y_train)\n",
    "\n",
    "#  meilleur modèle pour prédire le premier dataset\n",
    "lasso_res = BestLasso_test.predict(X_train)\n",
    "\n",
    "# marge d'erreur du modèle\n",
    "lasso = abs(lasso_res - y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrainement \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# création d'une instance du modèle RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor(n_estimators=100,max_depth=3, random_state=42)  \n",
    "\n",
    "# Entraînement du modèle sur les données d'entraînement\n",
    "rf_reg.fit(X_train, y_train)\n",
    "\n",
    "#prédictions sur les données d'entraînement\n",
    "y_train_hat_rf = rf_reg.predict(X_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test \n",
    "# création d'une instance du modèle RandomForestRegressor\n",
    "rf_reg_test = RandomForestRegressor(n_estimators=100, random_state=42)  \n",
    "\n",
    "# Entraînement du modèle sur les données d'entraînement\n",
    "rf_reg_test.fit(X_test, y_test)\n",
    "\n",
    "#prédictions sur les données d'entraînement\n",
    "y_train_hat_rf = rf_reg_test.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrainement \n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Créez une instance du modèle XGBoost pour la régression\n",
    "xgb_reg = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',  # Pour la régression\n",
    "    learning_rate=1,             # Taux d'apprentissage\n",
    "    n_estimators=2,              # Nombre d'estimateurs (arbres)\n",
    "    max_depth=16,                   # Profondeur maximale de l'arbre\n",
    "    # subsample=0.8,                 # Sous-échantillonnage des lignes\n",
    "    # colsample_bytree=0.8,          # Sous-échantillonnage des colonnes\n",
    "    # gamma=0,                       # Paramètre de régularisation\n",
    "    # reg_lambda=1,                  # Régularisation L2\n",
    "    # reg_alpha=0,                   # Régularisation L1\n",
    "    # min_child_weight=1             # Poids minimal des feuilles\n",
    ")\n",
    "\n",
    "# Entraînez le modèle sur les données d'entraînement\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "\n",
    "# Faites des prédictions sur les données de test\n",
    "y_test_hat_xgb = xgb_reg.predict(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test \n",
    "\n",
    "# Créez une instance du modèle XGBoost pour la régression\n",
    "xgb_reg_test = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',  # Pour la régression\n",
    "    learning_rate=1,             # Taux d'apprentissage\n",
    "    n_estimators=2,              # Nombre d'estimateurs (arbres)\n",
    "    max_depth=16,                   # Profondeur maximale de l'arbre\n",
    "    # subsample=0.8,                 # Sous-échantillonnage des lignes\n",
    "    # colsample_bytree=0.8,          # Sous-échantillonnage des colonnes\n",
    "    # gamma=0,                       # Paramètre de régularisation\n",
    "    # reg_lambda=1,                  # Régularisation L2\n",
    "    # reg_alpha=0,                   # Régularisation L1\n",
    "    # min_child_weight=1             # Poids minimal des feuilles\n",
    ")\n",
    "\n",
    "# Entraînez le modèle sur les données d'entraînement\n",
    "xgb_reg_test.fit(X_test, y_test)\n",
    "\n",
    "# Faites des prédictions sur les données de test\n",
    "y_test_hat_xgb = xgb_reg_test.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "def model_evaluator(model_trained):\n",
    "  temp_y_train_hat = model_trained.predict(X_train)\n",
    "  print(\"MAE : \", mean_absolute_error(y_train, temp_y_train_hat))\n",
    "  print(\"MSE : \", mean_squared_error(y_train, temp_y_train_hat))\n",
    "  print(\"MAPE : \", mean_absolute_percentage_error(y_train, temp_y_train_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_scores = []\n",
    "\n",
    "for i_estimator in range(2, 8, 2): \n",
    "  for depth_estimator in range(10, 18, 2): \n",
    "    bst = xgb.XGBRegressor(n_estimators=i_estimator, max_depth=depth_estimator,\n",
    "                      learning_rate=1, n_jobs=-1)\n",
    "    # fit model\n",
    "    bst.fit(X_train, y_train)\n",
    "    y_train_hat = bst.predict(X_train)\n",
    "    y_test_hat = bst.predict(X_test)\n",
    "    list_scores.append({\n",
    "        \"n_estimator\": i_estimator,\n",
    "        \"max_depth\": depth_estimator,\n",
    "        \"train_mae\":mean_absolute_error(y_train, y_train_hat) ,\n",
    "        \"test_mae\": mean_absolute_error(y_test, y_test_hat),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_estimator</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_mae</th>\n",
       "      <th>test_mae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>49.557979</td>\n",
       "      <td>68.360201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>48.060194</td>\n",
       "      <td>68.581148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>44.577385</td>\n",
       "      <td>68.755617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>41.494598</td>\n",
       "      <td>69.187106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>50.501148</td>\n",
       "      <td>69.654047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>54.902189</td>\n",
       "      <td>69.754210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>39.304985</td>\n",
       "      <td>70.101919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>47.057596</td>\n",
       "      <td>70.105083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>53.225465</td>\n",
       "      <td>70.366389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>37.628948</td>\n",
       "      <td>70.474583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>43.762837</td>\n",
       "      <td>70.814393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>46.010471</td>\n",
       "      <td>70.858794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>60.451602</td>\n",
       "      <td>72.560456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>55.544875</td>\n",
       "      <td>73.514693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>53.953656</td>\n",
       "      <td>73.673171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>51.913388</td>\n",
       "      <td>74.011426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>59.553752</td>\n",
       "      <td>74.097031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>50.690666</td>\n",
       "      <td>74.541335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>64.393283</td>\n",
       "      <td>77.678402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>63.230151</td>\n",
       "      <td>78.391829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_estimator  max_depth  train_mae   test_mae\n",
       "5             2         15  49.557979  68.360201\n",
       "11            3         15  48.060194  68.581148\n",
       "17            4         15  44.577385  68.755617\n",
       "23            5         15  41.494598  69.187106\n",
       "16            4         14  50.501148  69.654047\n",
       "4             2         14  54.902189  69.754210\n",
       "29            6         15  39.304985  70.101919\n",
       "22            5         14  47.057596  70.105083\n",
       "10            3         14  53.225465  70.366389\n",
       "35            7         15  37.628948  70.474583\n",
       "34            7         14  43.762837  70.814393\n",
       "28            6         14  46.010471  70.858794\n",
       "3             2         13  60.451602  72.560456\n",
       "15            4         13  55.544875  73.514693\n",
       "21            5         13  53.953656  73.673171\n",
       "27            6         13  51.913388  74.011426\n",
       "9             3         13  59.553752  74.097031\n",
       "33            7         13  50.690666  74.541335\n",
       "8             3         12  64.393283  77.678402\n",
       "14            4         12  63.230151  78.391829"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.DataFrame(list_scores).sort_values(by=\"test_mae\").head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jawad\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:160: UserWarning: [15:11:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-mae:360.90066\ttrain-mae:359.14552             \n",
      "[1]\teval-mae:350.29000\ttrain-mae:348.85073             \n",
      "[2]\teval-mae:338.98709\ttrain-mae:337.11634             \n",
      "  0%|          | 0/150 [00:00<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[113], line 50\u001b[0m\n\u001b[0;32m     45\u001b[0m   best \u001b[38;5;241m=\u001b[39m fmin(score, space, algo\u001b[38;5;241m=\u001b[39mtpe\u001b[38;5;241m.\u001b[39msuggest, \n\u001b[0;32m     46\u001b[0m                 \u001b[38;5;66;03m# trials=trials, \u001b[39;00m\n\u001b[0;32m     47\u001b[0m                 max_evals\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m)\n\u001b[0;32m     48\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m best\n\u001b[1;32m---> 50\u001b[0m best_hyperparams \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# trials\u001b[39;49;00m\n\u001b[0;32m     52\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe best hyperparameters are: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(best_hyperparams)\n",
      "Cell \u001b[1;32mIn[113], line 45\u001b[0m, in \u001b[0;36moptimize\u001b[1;34m(random_state)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# trials,\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4242\u001b[39m\n\u001b[0;32m     24\u001b[0m ):\n\u001b[0;32m     25\u001b[0m   space \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     26\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: hp\u001b[38;5;241m.\u001b[39mquniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m     27\u001b[0m       \u001b[38;5;66;03m# 'eta': hp.quniform('eta', 0.025, 0.5, 0.025),\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m'\u001b[39m: random_state\n\u001b[0;32m     44\u001b[0m   }\n\u001b[1;32m---> 45\u001b[0m   best \u001b[38;5;241m=\u001b[39m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# trials=trials, \u001b[39;49;00m\n\u001b[0;32m     47\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m best\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\hyperopt\\fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[0;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\hyperopt\\fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\hyperopt\\fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\hyperopt\\fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\hyperopt\\base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[0;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[0;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[0;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[1;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[0;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n",
      "Cell \u001b[1;32mIn[113], line 11\u001b[0m, in \u001b[0;36mscore\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m      9\u001b[0m dvalid \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mDMatrix(X_test, label\u001b[38;5;241m=\u001b[39my_test)\n\u001b[0;32m     10\u001b[0m watchlist \u001b[38;5;241m=\u001b[39m [(dvalid, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m'\u001b[39m), (dtrain, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m---> 11\u001b[0m gbm_model \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwatchlist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m predictions \u001b[38;5;241m=\u001b[39m gbm_model\u001b[38;5;241m.\u001b[39mpredict(dvalid)\n\u001b[0;32m     15\u001b[0m score \u001b[38;5;241m=\u001b[39m mean_absolute_error(y_test, predictions)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:2051\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2047\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2050\u001b[0m     _check_call(\n\u001b[1;32m-> 2051\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2052\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[0;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2054\u001b[0m     )\n\u001b[0;32m   2055\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2056\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import hyperopt as hp\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "import xgboost as xgb\n",
    "\n",
    "def score(params):\n",
    "    num_round = int(params['n_estimators'])\n",
    "    del params['n_estimators']\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dvalid = xgb.DMatrix(X_test, label=y_test)\n",
    "    watchlist = [(dvalid, 'eval'), (dtrain, 'train')]\n",
    "    gbm_model = xgb.train(params, dtrain, num_round,\n",
    "                          evals=watchlist,\n",
    "                          verbose_eval=True)\n",
    "    predictions = gbm_model.predict(dvalid)\n",
    "    score = mean_absolute_error(y_test, predictions)\n",
    "    # TODO: Add the importance for the selected features\n",
    "    # The score function should return the loss (1-score)\n",
    "    # since the optimize function looks for the minimum\n",
    "    return {'loss': score, 'status': STATUS_OK}\n",
    "\n",
    "def optimize(\n",
    "    # trials,\n",
    "    random_state=4242\n",
    "):\n",
    "  space = {\n",
    "      'n_estimators': hp.quniform('n_estimators', 10, 50, 1),\n",
    "      # 'eta': hp.quniform('eta', 0.025, 0.5, 0.025),\n",
    "      # A problem with max_depth casted to float instead of int with\n",
    "      # the hp.quniform method.\n",
    "      'max_depth':  hp.choice('max_depth', np.arange(1, 14, dtype=int)),\n",
    "      # 'min_child_weight': hp.quniform('min_child_weight', 1, 6, 1),\n",
    "      # 'subsample': hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "      # 'gamma': hp.quniform('gamma', 0.5, 1, 0.05),\n",
    "      # 'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n",
    "      'eval_metric': 'mae',\n",
    "      # 'objective': 'binary:logistic',\n",
    "      # Increase this number if you have more cores. Otherwise, remove it and it will default\n",
    "      # to the maxium number.\n",
    "      'nthread': 4,\n",
    "      'booster': 'gbtree',\n",
    "      'tree_method': 'exact',\n",
    "      'silent': 1,\n",
    "      'seed': random_state\n",
    "  }\n",
    "  best = fmin(score, space, algo=tpe.suggest, \n",
    "                # trials=trials, \n",
    "                max_evals=150)\n",
    "  return best\n",
    "\n",
    "best_hyperparams = optimize(\n",
    "    # trials\n",
    ")\n",
    "print(\"The best hyperparameters are: \", \"\\n\")\n",
    "print(best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE :  367.32535901350946\n",
      "MSE :  814975.2644089637\n",
      "MAPE :  2.1477637613182426e+17\n",
      "\n",
      "\n",
      "MAE :  369.32853004749427\n",
      "MSE :  814986.0320698202\n",
      "MAPE :  2.1735971654892208e+17\n"
     ]
    }
   ],
   "source": [
    "model_evaluator(dummy_regr)\n",
    "print('\\n')\n",
    "model_evaluator(dummy_regr_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE :  363.30870002994044\n",
      "MSE :  715675.2467702781\n",
      "MAPE :  1.6423129735370653e+17\n",
      "\n",
      "\n",
      "MAE :  365.8670507002546\n",
      "MSE :  715774.6759495926\n",
      "MAPE :  1.676378698492671e+17\n"
     ]
    }
   ],
   "source": [
    "model_evaluator(reg)\n",
    "print('\\n')\n",
    "model_evaluator(reg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE :  363.21141595897046\n",
      "MSE :  715686.1911543095\n",
      "MAPE :  1.6413497124993763e+17\n",
      "\n",
      "\n",
      "MAE :  363.21141595897046\n",
      "MSE :  715686.1911543095\n",
      "MAPE :  1.6413497124993763e+17\n"
     ]
    }
   ],
   "source": [
    "model_evaluator(BestLasso)\n",
    "print('\\n')\n",
    "model_evaluator(BestLasso_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE :  17.379511747779414\n",
      "MSE :  4213.471042108565\n",
      "MAPE :  131014254870199.84\n",
      "\n",
      "\n",
      "MAE :  63.696891892592085\n",
      "MSE :  50325.2802193782\n",
      "MAPE :  915758744549116.9\n"
     ]
    }
   ],
   "source": [
    "model_evaluator(rf_reg)\n",
    "print('\\n')\n",
    "model_evaluator(rf_reg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE :  45.14158192605164\n",
      "MSE :  21778.0446873478\n",
      "MAPE :  1884705793687621.8\n",
      "\n",
      "\n",
      "MAE :  80.81226373250209\n",
      "MSE :  79858.11197789201\n",
      "MAPE :  3766627407051585.5\n"
     ]
    }
   ],
   "source": [
    "model_evaluator(xgb_reg)\n",
    "print('\\n')\n",
    "model_evaluator(xgb_reg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
